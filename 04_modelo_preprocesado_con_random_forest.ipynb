{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MODELO: RANDOM FOREST"
      ],
      "metadata": {
        "id": "yQtdz0L-pCDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. CONFIGURACIÓN E IMPORTACIONES"
      ],
      "metadata": {
        "id": "oA6OimoApYAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "# Limpiar salidas molestas\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "AT6J-JQak808"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. CARGA DE DATOS\n"
      ],
      "metadata": {
        "id": "eFPNaMpNpeFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "\n",
        "!unzip udea*.zip > /dev/null\n",
        "!wc *.csv\n",
        "\n",
        "print(\"Cargando datasets para Random Forest...\")\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m93sZXgVk8qW",
        "outputId": "91905940-6b78-4709-b3b9-a934eb67d3fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 1.06GB/s]\n",
            "   296787    296787   4716673 submission_example.csv\n",
            "   296787   4565553  59185238 test.csv\n",
            "   692501  10666231 143732437 train.csv\n",
            "  1286075  15528571 207634348 total\n",
            "Cargando datasets para Random Forest...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3. PREPROCESAMIENTO"
      ],
      "metadata": {
        "id": "_aoACuaGpmEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpieza_random_forest(df_input):\n",
        "    df = df_input.copy()\n",
        "\n",
        "    # A. Eliminar columnas con un solo valor (no aportan info)\n",
        "    for col in df.columns:\n",
        "        if df[col].nunique(dropna=False) <= 1:\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    # B. Ingeniería de Características Básica\n",
        "    # Suma de educación de padres (Capital Educativo)\n",
        "    # Mapeamos primero para poder sumar\n",
        "    mapa_edu = {\n",
        "        'Ninguno': 0, 'No sabe': 0, 'Primaria incompleta': 1, 'Primaria completa': 2,\n",
        "        'Secundaria (Bachillerato) incompleta': 3, 'Secundaria (Bachillerato) completa': 4,\n",
        "        'Técnica o tecnológica incompleta': 5, 'Técnica o tecnológica completa': 6,\n",
        "        'Postgrado': 7\n",
        "    }\n",
        "    col_padres = ['F_EDUCACIONPADRE', 'F_EDUCACIONMADRE']\n",
        "    if all(c in df.columns for c in col_padres):\n",
        "        # Llenamos temporalmente con 0 para sumar\n",
        "        edu_padre = df['F_EDUCACIONPADRE'].map(mapa_edu).fillna(0)\n",
        "        edu_madre = df['F_EDUCACIONMADRE'].map(mapa_edu).fillna(0)\n",
        "        df['CAPITAL_EDUCATIVO_RF'] = edu_padre + edu_madre\n",
        "\n",
        "    # C. Tratamiento de Nulos y Categóricas\n",
        "    # Iteramos sobre todas las columnas\n",
        "    for col in df.columns:\n",
        "        # 1. Si es numérica (float/int)\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            # Rellenar nulos con un valor fuera de rango (-999)\n",
        "            # Esto ayuda al árbol a separar los que tenían datos de los que no\n",
        "            df[col] = df[col].fillna(-999)\n",
        "\n",
        "        # 2. Si es objeto (texto) o categoría\n",
        "        else:\n",
        "            # Rellenar nulos con string explícito\n",
        "            df[col] = df[col].fillna('SIN_DATO')\n",
        "            # Convertir a números (Label Encoding rápido)\n",
        "            df[col] = df[col].astype('str').astype('category').cat.codes\n",
        "\n",
        "    return df\n",
        "\n",
        "print(\"Procesando datos (rellenando nulos y codificando)...\")\n",
        "\n",
        "# Separamos X e y\n",
        "X_raw = df_train.drop(columns=['RENDIMIENTO_GLOBAL', 'ID'])\n",
        "X_submission_raw = df_test.drop(columns=['ID'])\n",
        "y_raw = df_train['RENDIMIENTO_GLOBAL']\n",
        "ids_test = df_test['ID']\n",
        "\n",
        "# Aplicamos la limpieza\n",
        "X = limpieza_random_forest(X_raw)\n",
        "X_sub = limpieza_random_forest(X_submission_raw)\n",
        "\n",
        "# Codificar Target\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "\n",
        "# Limpieza de memoria\n",
        "del df_train, df_test, X_raw, X_submission_raw\n",
        "gc.collect()\n",
        "\n",
        "print(f\"Dimensiones listas: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlDWnkSVk8hf",
        "outputId": "0ee6abd4-9fad-4bd3-f0ee-8cb82a42676a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesando datos (rellenando nulos y codificando)...\n",
            "Dimensiones listas: (692500, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4. CONFIGURACIÓN DEL MODELO"
      ],
      "metadata": {
        "id": "JrPGmyqSpwNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el Random Forest\n",
        "# Ajustamos parámetros para que no tarde demasiado pero sea preciso\n",
        "bosque = RandomForestClassifier(\n",
        "    n_estimators=300,        # Número de árboles (300 es robusto)\n",
        "    criterion='gini',        # Criterio de división estándar\n",
        "    max_depth=18,            # Profundidad máxima (evita archivos gigantes y lentitud)\n",
        "    min_samples_split=5,     # Mínimo de datos para dividir un nodo\n",
        "    min_samples_leaf=2,      # Mínimo de datos en una hoja\n",
        "    max_features='sqrt',     # Número de features a considerar en cada división\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,               # Usar todos los núcleos del CPU\n",
        "    random_state=123,        # Semilla diferente a los otros modelos\n",
        "    verbose=0\n",
        ")"
      ],
      "metadata": {
        "id": "Pv27nFJNk8WP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. VALIDACIÓN (Split 80/20)"
      ],
      "metadata": {
        "id": "4Z1zEyUnp4Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Fase 1: Validación Interna ---\")\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123, stratify=y)\n",
        "\n",
        "print(\"Entrenando bosque en set de validación...\")\n",
        "bosque.fit(X_train, y_train)\n",
        "\n",
        "# Evaluación\n",
        "preds_val = bosque.predict(X_val)\n",
        "acc = accuracy_score(y_val, preds_val)\n",
        "print(f\">>> Accuracy Estimado (Random Forest): {acc:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OngXLArik8I_",
        "outputId": "8c1170fc-9619-45b6-e1c9-a2484c1245c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fase 1: Validación Interna ---\n",
            "Entrenando bosque en set de validación...\n",
            ">>> Accuracy Estimado (Random Forest): 0.41126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. ENTRENAMIENTO FINAL Y SUBMISSION"
      ],
      "metadata": {
        "id": "rtzjoF3pp9oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Fase 2: Entrenamiento con dataset COMPLETO ---\")\n",
        "# Entrenamos con TODO (X, y) para el archivo final\n",
        "bosque.fit(X, y)\n",
        "\n",
        "print(\"Generando predicciones finales...\")\n",
        "preds_codigos = bosque.predict(X_sub)\n",
        "preds_etiquetas = le.inverse_transform(preds_codigos)\n",
        "\n",
        "# Guardar Archivo\n",
        "nombre_archivo = 'submission_random_forest.csv'\n",
        "df_export = pd.DataFrame({'ID': ids_test, 'RENDIMIENTO_GLOBAL': preds_etiquetas})\n",
        "df_export.to_csv(nombre_archivo, index=False)\n",
        "\n",
        "print(f\"¡Hecho! Archivo generado: {nombre_archivo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFSK9OXlk71e",
        "outputId": "9f40c7f3-5f34-4efe-ec57-a27796e64913"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fase 2: Entrenamiento con dataset COMPLETO ---\n",
            "Generando predicciones finales...\n",
            "¡Hecho! Archivo generado: submission_random_forest.csv\n"
          ]
        }
      ]
    }
  ]
}