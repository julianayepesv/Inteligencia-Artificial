{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MODELO SOLUCIÓN: LIGHTGBM"
      ],
      "metadata": {
        "id": "ez1jxKdctvtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importación de Librerías y Definición de Mapeos Se instalan las dependencias necesarias (LightGBM) y se definen diccionarios de configuración (CFG_MAPS) para transformar variables categóricas ordinales (como educación y estratos) en valores numéricos interpretables por el modelo."
      ],
      "metadata": {
        "id": "w5ezQphBs_JK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJj1MbitRn4x"
      },
      "outputs": [],
      "source": [
        "!pip install lightgbm -q --upgrade\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "# Silenciar advertencias innecesarias\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# DICCIONARIOS DE CONFIGURACIÓN\n",
        "CFG_MAPS = {\n",
        "    'binario': {'Si': 1, 'No': 0, 'S': 1, 'N': 0},\n",
        "    'educacion': {\n",
        "        'Ninguno': 0, 'No sabe': 0, 'Primaria incompleta': 1, 'Primaria completa': 2,\n",
        "        'Secundaria (Bachillerato) incompleta': 3, 'Secundaria (Bachillerato) completa': 4,\n",
        "        'Técnica o tecnológica incompleta': 5, 'Técnica o tecnológica completa': 6,\n",
        "        'Postgrado': 7\n",
        "    },\n",
        "    'estrato': lambda x: str(x).replace('Estrato ', '').replace('Sin Estrato', '0').replace('nan', '0'),\n",
        "    'matricula': {\n",
        "        'No pagó matrícula': 0, 'Menos de 500 mil': 1,\n",
        "        'Entre 500 mil y menos de 1 millón': 2, 'Entre 1 millón y menos de 2.5 millones': 3,\n",
        "        'Entre 2.5 millones y menos de 4 millones': 4, 'Entre 4 millones y menos de 5.5 millones': 5,\n",
        "        'Entre 5.5 millones y menos de 7 millones': 6, 'Más de 7 millones': 7\n",
        "    },\n",
        "    'trabajo': {\n",
        "        '0': 0, 'Menos de 10 horas': 1, 'Entre 11 y 20 horas': 2,\n",
        "        'Entre 21 y 30 horas': 3, 'Más de 30 horas': 4\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingesta de Datos desde API de Kaggle Configuración del entorno para descargar el dataset directamente desde la competición utilizando la API de Kaggle, asegurando acceso rápido y reproducible a los archivos train.csv y test.csv."
      ],
      "metadata": {
        "id": "jQfhbXzUtDaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "!chmod 600 kaggle.json 2>/dev/null\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia --force\n",
        "!unzip -o udea*.zip > /dev/null\n",
        "print(\"Archivos disponibles:\")\n",
        "!ls *.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rewlb4DBRxrN",
        "outputId": "fbd2ba38-8050-4e77-d4c8-85a542046177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 522MB/s]\n",
            "Archivos disponibles:\n",
            "submission_example.csv\ttest.csv  train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesamiento e Ingeniería de Características Función central que limpia los datos, aplica los mapeos definidos, gestiona valores nulos y crea nuevas variables sintéticas (como Capital Educativo). Finalmente, prepara las matrices X (features) y y (target) para el entrenamiento."
      ],
      "metadata": {
        "id": "Pv1uzIHqtIZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(df_raw):\n",
        "    \"\"\"\n",
        "    Transforma el dataframe aplicando mappings y creando nuevas variables.\n",
        "    \"\"\"\n",
        "    df = df_raw.copy()\n",
        "\n",
        "    # 1. Limpieza de Estrato (Aplicando la lambda definida arriba)\n",
        "    if 'F_ESTRATOVIVIENDA' in df.columns:\n",
        "        df['F_ESTRATOVIVIENDA'] = df['F_ESTRATOVIVIENDA'].apply(CFG_MAPS['estrato']).astype(float)\n",
        "\n",
        "    # 2. Mapeos Ordinales (Educación, Matrícula, Trabajo)\n",
        "    col_mappings = {\n",
        "        'F_EDUCACIONPADRE': CFG_MAPS['educacion'],\n",
        "        'F_EDUCACIONMADRE': CFG_MAPS['educacion'],\n",
        "        'E_VALORMATRICULAUNIVERSIDAD': CFG_MAPS['matricula'],\n",
        "        'E_HORASSEMANATRABAJA': CFG_MAPS['trabajo']\n",
        "    }\n",
        "\n",
        "    for col, mapping in col_mappings.items():\n",
        "        if col in df.columns:\n",
        "            # Usamos map, pero llenamos NaN con -1 para que el modelo sepa que falta\n",
        "            df[col] = df[col].map(mapping).fillna(-1)\n",
        "\n",
        "    # 3. Variables Binarias (Detección automática de columnas por nombre)\n",
        "    cols_binarias = [c for c in df.columns if 'TIENE' in c or 'PRIVADO' in c or 'PAGO' in c]\n",
        "    for col in cols_binarias:\n",
        "        df[col] = df[col].map(CFG_MAPS['binario']).fillna(-1)\n",
        "\n",
        "    # 4. Creación de Características (Feature Creation)\n",
        "    # Suma de capital educativo (Padre + Madre)\n",
        "    if 'F_EDUCACIONPADRE' in df.columns and 'F_EDUCACIONMADRE' in df.columns:\n",
        "        df['S_CAPITAL_EDUCATIVO'] = df['F_EDUCACIONPADRE'] + df['F_EDUCACIONMADRE']\n",
        "\n",
        "    # Optimización de Tipos\n",
        "    # Convertir columnas tipo 'object' a 'category' es CRÍTICO para LightGBM\n",
        "    cat_cols = df.select_dtypes(include=['object']).columns\n",
        "    for col in cat_cols:\n",
        "        if col not in ['ID', 'RENDIMIENTO_GLOBAL']:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Carga y proceso\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Eliminación de columnas constantes (varianza 0)\n",
        "const_cols = [c for c in train.columns if train[c].nunique(dropna=False) <= 1]\n",
        "train.drop(columns=const_cols, inplace=True)\n",
        "test.drop(columns=const_cols, errors='ignore', inplace=True)\n",
        "\n",
        "# Transformación\n",
        "X_full = feature_engineering(train.drop(columns=['RENDIMIENTO_GLOBAL', 'ID']))\n",
        "y_full = train['RENDIMIENTO_GLOBAL']\n",
        "X_test = feature_engineering(test.drop(columns=['ID']))\n",
        "\n",
        "# Encoding del Target\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y_full)\n",
        "\n",
        "print(f\"Features finales: {X_full.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kb-AKmNR6U0",
        "outputId": "2cc5afab-a32d-496f-d8c5-a36e6802c567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features finales: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento con Validación Cruzada Estratificada (Stratified K-Fold) Configuración de hiperparámetros de LightGBM y entrenamiento iterativo utilizando 5 pliegues (Folds). Esto genera predicciones más robustas y evita el sobreajuste (overfitting)."
      ],
      "metadata": {
        "id": "Ah9bfE8JtXNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros optimizados para estabilidad\n",
        "LGBM_PARAMS = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': len(le.classes_),\n",
        "    'metric': 'multi_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.035,   # Ligeramente más bajo para mayor precisión\n",
        "    'num_leaves': 45,\n",
        "    'max_depth': 10,\n",
        "    'feature_fraction': 0.8,  # Selecciona 80% de features por árbol (evita overfit)\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': -1,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Estrategia: Stratified K-Fold\n",
        "FOLDs = 5\n",
        "skf = StratifiedKFold(n_splits=FOLDs, shuffle=True, random_state=42)\n",
        "\n",
        "# Matrices para guardar resultados\n",
        "oof_preds = np.zeros((len(X_full), len(le.classes_)))\n",
        "test_preds = np.zeros((len(X_test), len(le.classes_)))\n",
        "\n",
        "print(f\"Iniciando entrenamiento con {FOLDs} Folds...\")\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_full, y_encoded)):\n",
        "    # Split de datos\n",
        "    X_train, y_train = X_full.iloc[train_idx], y_encoded[train_idx]\n",
        "    X_val, y_val = X_full.iloc[val_idx], y_encoded[val_idx]\n",
        "\n",
        "    # Crear datasets de LightGBM\n",
        "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
        "    dval = lgb.Dataset(X_val, label=y_val, reference=dtrain)\n",
        "\n",
        "    # Entrenar\n",
        "    model = lgb.train(\n",
        "        LGBM_PARAMS,\n",
        "        dtrain,\n",
        "        num_boost_round=2000, # Damos mucho espacio\n",
        "        valid_sets=[dtrain, dval],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
        "            lgb.log_evaluation(period=0) # Silenciar log masivo\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Predecir validación y test\n",
        "    oof_preds[val_idx] = model.predict(X_val)\n",
        "    test_preds += model.predict(X_test) / FOLDs # Promediamos las predicciones\n",
        "\n",
        "    # Score del fold actual\n",
        "    acc_fold = accuracy_score(y_val, np.argmax(oof_preds[val_idx], axis=1))\n",
        "    print(f\"Fold {fold+1}: Accuracy = {acc_fold:.4f}\")\n",
        "\n",
        "# Evaluación Global\n",
        "acc_global = accuracy_score(y_encoded, np.argmax(oof_preds, axis=1))\n",
        "print(f\"\\n--- Accuracy Promedio Global: {acc_global:.5f} ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nlpkV6fR9j0",
        "outputId": "19d769b1-4396-47d5-b502-4bbc8f36a1c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando entrenamiento con 5 Folds...\n",
            "Fold 1: Accuracy = 0.4416\n",
            "Fold 2: Accuracy = 0.4390\n",
            "Fold 3: Accuracy = 0.4390\n",
            "Fold 4: Accuracy = 0.4414\n",
            "Fold 5: Accuracy = 0.4405\n",
            "\n",
            "--- Accuracy Promedio Global: 0.44030 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación del Archivo de Submission Decodificación de las predicciones numéricas a sus etiquetas originales y creación del archivo .csv final para subir a la plataforma."
      ],
      "metadata": {
        "id": "7n7Lk_KkthAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir probabilidades a etiquetas finales\n",
        "predicciones_finales_indices = np.argmax(test_preds, axis=1)\n",
        "etiquetas_finales = le.inverse_transform(predicciones_finales_indices)\n",
        "\n",
        "# Guardar\n",
        "nombre_sub = 'submission_kfold_ensemble.csv'\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test['ID'],\n",
        "    'RENDIMIENTO_GLOBAL': etiquetas_finales\n",
        "})\n",
        "\n",
        "submission.to_csv(nombre_sub, index=False)\n",
        "print(f\"Archivo generado exitosamente: {nombre_sub}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EyKcJBOSB3I",
        "outputId": "aa458c1d-6498-4f1e-ec9b-e13e9c1dc1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo generado exitosamente: submission_kfold_ensemble.csv\n"
          ]
        }
      ]
    }
  ]
}